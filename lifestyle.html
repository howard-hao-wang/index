<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Life</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
    }
    header {
      background-color: #f4f4f4;
      padding: 20px;
      text-align: center;
    }
    nav {
      display: flex;
      justify-content: center;
      background-color: #333;
    }
    nav a {
      color: white;
      padding: 14px 20px;
      text-decoration: none;
      text-align: center;
    }
    nav a:hover {
      background-color: #575757;
    }
    section {
      padding: 20px;
    }
    h2 {
      color: #333;
      border-bottom: 2px solid #ddd;
      padding-bottom: 5px;
    }
    p {
      margin-bottom: 20px;
    }
    .gallery {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 20px;
    }
    .gallery img {
      width: 100%;
      height: auto;
      border-radius: 5px;
    }
    .caption {
      text-align: center;
      margin-top: 5px;
      font-weight: bold;
    }
    footer {
      text-align: center;
      padding: 10px;
      background-color: #f4f4f4;
      margin-top: 20px;
    }
  </style>
</head>
<body>
  <header>
    <h1>Lifestyle</h1>
    <p>A glimpse into my hobbies and adventures</p>
  </header>
  <nav>
    <a href="index.html">Home</a>
    <a href="book_project.html">Book Project</a>
    <a href="research.html">Research Papers</a>
    <a href="teaching.html">Teaching</a>
    <a href="academic_activities.html">Academic Activities</a>
    <a href="resources.html">Resources</a>
    <a href="lifestyle.html">Lifestyle</a>

  </nav>
  <section>
    <h2> Academic pursuits are like hiking in the wilderness—every journey of a thousand miles begins with a single step. </h2>
    <p>
      I'm a hiking enthusiast and dabble in fitness ever since graduation—trying to stay in shape, you know. Occasionally, you'll catch me shooting hoops, smashing ping-pong balls, taking a dip in the pool, or plotting my next move in a game of Chinese chess.
    </p>

    <h2>Photo Gallery</h2>
    <div class="gallery">

      <div>
        <img src="20141004 船底顶.jpg" alt="">
        <div class="caption">Oct 4, 2014, 船底顶</div>
      </div>
      <div>
        <img src="20170901, Qomolangma.JPG" alt="">
        <div class="caption">Sep 1, 2017, Qomolangma</div>
      </div>
      <div>
        <img src="20211120 大屿山.jpg" alt="">
        <div class="caption">Nov 20, 2021, Lantau Island</div>
      </div>
      <div>
        <img src="20211120 大屿山2.jpg" alt="">
        <div class="caption">Nov 20, 2021, Lantau Island</div>
      </div>
      <div>
        <img src="20220918奥地利与斯洛伐克边境旅游.jpg" alt="">
        <div class="caption">Sep 18, 2022, the Austria-Slovakia border</div>
      </div>
      <div>
        <img src="20231223 环湖出咀.jpg" alt="">
        <div class="caption">Dec 23, 2023, Hong Kong Devil's Fist 鬼手岩(https://www.oasistrek.com/devils_fist.php)</div>
      </div>
      <div>
        <img src="20241110 The classroom where inspired me.jpg" alt="">
        <div class="caption">Nov 10, 2024, the classroom where inspired me</div>
      </div>
    </div>

    <h2> Reading Notes </h2>
    <p> 20251007 daily routine </p>

1. AI and welfare in government policy decision
Article
Open access
Published: 29 July 2025
Heterogeneous preferences and asymmetric insights for AI use among welfare claimants and non-claimants
Mengchen Dong, Jean-François Bonnefon & Iyad Rahwan 
Nature Communications volume 16, Article number: 6973 (2025) Cite this article

## Abstract
The deployment of AI in welfare benefit allocation accelerates decision-making but has led to unfair denials and false fraud accusations. In the US and UK (N = 3249), we examine public acceptability of speed-accuracy trade-offs among claimants and non-claimants. While the public generally tolerates modest accuracy losses for faster decisions, claimants are less willing to accept AI in welfare systems, raising concerns that using aggregate data for calibration could misalign policies with the preferences of those most affected. Our study further uncovers asymmetric insights between claimants and non-claimants. Non-claimants overestimate claimants’ willingness to accept speed-accuracy trade-offs, even when financially incentivized for accurate perspective-taking. This suggests that policy decisions aimed at supporting vulnerable groups may need to incorporate minority voices beyond popular opinion, as non-claimants may not easily understand claimants’ perspectives.

## Introduction
The use of Artificial Intelligence (AI) is becoming commonplace in government operations1,2,3,4. In the United States alone, a 2020 survey of 142 federal agencies found that 45% were using or planning to use machine learning algorithms to streamline their operations, increase their capacities, or improve the delivery of their public services2.

the main promise of AI is to speed up decisions1,5,6

the general public values speed and accuracy in government services.

balancing speed gains and accuracy losses.

However, less is known about the extent of divergence in AI performance preferences and reconciliation between different perspectives and interests.

The combination of heterogeneous preferences and asymmetric insights creates the risk of welfare AI systems being aligned with the position of the largest, best understood, least vulnerable group – silencing the voice of the smallest, least understood, most vulnerable group, which nevertheless comprises the primary stakeholders in the deployment of welfare AI.

## Discussion
One primary advantage of using AI for welfare benefit allocation is quicker decision-making, allowing claimants to receive support faster1,5,6. However, these systems often result in an accuracy loss, potentially leading to unfair denials or false fraud accusations5,6,7,8,9,10. Governments deploying welfare AI systems may need to navigate these trade-offs carefully, particularly given their potential impacts on public trust18,31. Our findings also suggest that the acceptability of these trade-off decisions is correlated with public trust in the government.
Collecting data from the US and UK (N = 3249), our study suggested that participants would trade a one-week speed gain for a 2.5 to 5 percentage point accuracy loss,

to consider the positionality of AI models [Cambo, S. A. & Gergle, D. Model Positionality and Computational Reflexivity: Promoting Reflexivity in Data. Science https://doi.org/10.48550/ARXIV.2203.07031 (2022).Return to ref 33 in article]

configuring AI in welfare systems

These decisions about whose values and preferences AI aligns with – often referred to as ‘the alignment problem’41,42,43 – can be justified by the realities of heterogeneous preferences and asymmetrical insights in the context of welfare decisions.[Conitzer, V. et al. Social Choice for AI Alignment: Dealing with Diverse Human Feedback. https://doi.org/10.48550/ARXIV.2404.10271 (2024).]
In reality, AI- and human-dominant government systems may face different challenges. For example, AI can be hyper-vigilant about anomalies8,9 and seen as inflexible in self-corrections18,19. In contrast, human public servants may discriminate against particular social groups, and such biased judgments may vary from person to person and induce inconsistencies and unfairness in welfare payments46,47. 




  </section>
  <footer>
    <p>Copyright © Howard H. WANG, 2025</p>
  </footer>
</body>
</html>
